{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860ad5ba",
   "metadata": {
    "papermill": {
     "duration": 0.007732,
     "end_time": "2022-02-19T20:23:59.084084",
     "exception": false,
     "start_time": "2022-02-19T20:23:59.076352",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "860ad5ba"
   },
   "source": [
    "### Train your own GAN in a few lines of code!\n",
    "See original StyleGAN2 ADA github repo here: https://github.com/NVlabs/stylegan2-ada-pytorch\n",
    "\n",
    "By using a pre-trained model along with data heavy data augmentation, we can train our own GAN with a very limited dataset (<1000 images). \n",
    "\n",
    "Make sure you have a GPU runtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc4b433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T20:23:59.102398Z",
     "iopub.status.busy": "2022-02-19T20:23:59.100907Z",
     "iopub.status.idle": "2022-02-19T20:24:33.138797Z",
     "shell.execute_reply": "2022-02-19T20:24:33.138260Z",
     "shell.execute_reply.started": "2022-02-19T20:13:23.734823Z"
    },
    "papermill": {
     "duration": 34.047985,
     "end_time": "2022-02-19T20:24:33.138936",
     "exception": false,
     "start_time": "2022-02-19T20:23:59.090951",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bfc4b433",
    "outputId": "4c2b75ba-30b1-4099-f3aa-8d1d7e070210",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspng\n",
      "  Downloading pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195 kB)\n",
      "\u001B[K     |████████████████████████████████| 195 kB 7.3 MB/s \n",
      "\u001B[?25hCollecting ninja\n",
      "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001B[K     |████████████████████████████████| 108 kB 72.4 MB/s \n",
      "\u001B[?25hCollecting imageio-ffmpeg==0.4.3\n",
      "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 26.9 MB 1.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.21.6)\n",
      "Installing collected packages: pyspng, ninja, imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.10.2.3 pyspng-0.1.0\n",
      "Cloning into 'stylegan2-ada-pytorch'...\n",
      "remote: Enumerating objects: 128, done.\u001B[K\n",
      "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001B[K\n",
      "Receiving objects: 100% (128/128), 1.12 MiB | 22.96 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "/content/stylegan2-ada-pytorch\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspng ninja imageio-ffmpeg==0.4.3\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch\n",
    "!pip install gdown \n",
    "%cd ./stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "154983f3",
   "metadata": {
    "papermill": {
     "duration": 0.030712,
     "end_time": "2022-02-19T20:24:33.200445",
     "exception": false,
     "start_time": "2022-02-19T20:24:33.169733",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "154983f3"
   },
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ce1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T20:24:33.269720Z",
     "iopub.status.busy": "2022-02-19T20:24:33.268854Z",
     "iopub.status.idle": "2022-02-19T20:25:00.965442Z",
     "shell.execute_reply": "2022-02-19T20:25:00.964801Z",
     "shell.execute_reply.started": "2022-02-19T20:14:43.665717Z"
    },
    "papermill": {
     "duration": 27.733911,
     "end_time": "2022-02-19T20:25:00.965590",
     "exception": false,
     "start_time": "2022-02-19T20:24:33.231679",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ad6ce1ee",
    "outputId": "cd1528c1-1e37-404c-c0ce-f1a8945eb239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 850/850 [00:26<00:00, 32.09it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool.py --source=/kaggle/input/ganyu-genshin-impact-anime-faces-gan-training/ganyu-final --dest=./datasets/ganyu.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd259a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T20:25:01.167364Z",
     "iopub.status.busy": "2022-02-19T20:25:01.166615Z",
     "iopub.status.idle": "2022-02-19T20:25:05.247903Z",
     "shell.execute_reply": "2022-02-19T20:25:05.247387Z",
     "shell.execute_reply.started": "2022-02-19T20:22:47.039075Z"
    },
    "papermill": {
     "duration": 4.182975,
     "end_time": "2022-02-19T20:25:05.248067",
     "exception": false,
     "start_time": "2022-02-19T20:25:01.065092",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "8bd259a4",
    "outputId": "97df0732-3942-4763-9610-fd6c618b3d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: train.py [OPTIONS]\r\n",
      "\r\n",
      "  Train a GAN using the techniques described in the paper \"Training Generative\r\n",
      "  Adversarial Networks with Limited Data\".\r\n",
      "\r\n",
      "  Examples:\r\n",
      "\r\n",
      "  # Train with custom dataset using 1 GPU.\r\n",
      "  python train.py --outdir=~/training-runs --data=~/mydataset.zip --gpus=1\r\n",
      "\r\n",
      "  # Train class-conditional CIFAR-10 using 2 GPUs.\r\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/cifar10.zip \\\r\n",
      "      --gpus=2 --cfg=cifar --cond=1\r\n",
      "\r\n",
      "  # Transfer learn MetFaces from FFHQ using 4 GPUs.\r\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/metfaces.zip \\\r\n",
      "      --gpus=4 --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\r\n",
      "\r\n",
      "  # Reproduce original StyleGAN2 config F.\r\n",
      "  python train.py --outdir=~/training-runs --data=~/datasets/ffhq.zip \\\r\n",
      "      --gpus=8 --cfg=stylegan2 --mirror=1 --aug=noaug\r\n",
      "\r\n",
      "  Base configs (--cfg):\r\n",
      "    auto       Automatically select reasonable defaults based on resolution\r\n",
      "               and GPU count. Good starting point for new datasets.\r\n",
      "    stylegan2  Reproduce results for StyleGAN2 config F at 1024x1024.\r\n",
      "    paper256   Reproduce results for FFHQ and LSUN Cat at 256x256.\r\n",
      "    paper512   Reproduce results for BreCaHAD and AFHQ at 512x512.\r\n",
      "    paper1024  Reproduce results for MetFaces at 1024x1024.\r\n",
      "    cifar      Reproduce results for CIFAR-10 at 32x32.\r\n",
      "\r\n",
      "  Transfer learning source networks (--resume):\r\n",
      "    ffhq256        FFHQ trained at 256x256 resolution.\r\n",
      "    ffhq512        FFHQ trained at 512x512 resolution.\r\n",
      "    ffhq1024       FFHQ trained at 1024x1024 resolution.\r\n",
      "    celebahq256    CelebA-HQ trained at 256x256 resolution.\r\n",
      "    lsundog256     LSUN Dog trained at 256x256 resolution.\r\n",
      "    <PATH or URL>  Custom network pickle.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --outdir DIR                    Where to save the results  [required]\r\n",
      "  --gpus INT                      Number of GPUs to use [default: 1]\r\n",
      "  --snap INT                      Snapshot interval [default: 50 ticks]\r\n",
      "  --metrics LIST                  Comma-separated list or \"none\" [default:\r\n",
      "                                  fid50k_full]\r\n",
      "  --seed INT                      Random seed [default: 0]\r\n",
      "  -n, --dry-run                   Print training options and exit\r\n",
      "  --data PATH                     Training data (directory or zip)  [required]\r\n",
      "  --cond BOOL                     Train conditional model based on dataset\r\n",
      "                                  labels [default: false]\r\n",
      "  --subset INT                    Train with only N images [default: all]\r\n",
      "  --mirror BOOL                   Enable dataset x-flips [default: false]\r\n",
      "  --cfg [auto|stylegan2|paper256|paper512|paper1024|cifar]\r\n",
      "                                  Base config [default: auto]\r\n",
      "  --gamma FLOAT                   Override R1 gamma\r\n",
      "  --kimg INT                      Override training duration\r\n",
      "  --batch INT                     Override batch size\r\n",
      "  --aug [noaug|ada|fixed]         Augmentation mode [default: ada]\r\n",
      "  --p FLOAT                       Augmentation probability for --aug=fixed\r\n",
      "  --target FLOAT                  ADA target value for --aug=ada\r\n",
      "  --augpipe [blit|geom|color|filter|noise|cutout|bg|bgc|bgcf|bgcfn|bgcfnc]\r\n",
      "                                  Augmentation pipeline [default: bgc]\r\n",
      "  --resume PKL                    Resume training [default: noresume]\r\n",
      "  --freezed INT                   Freeze-D [default: 0 layers]\r\n",
      "  --fp32 BOOL                     Disable mixed-precision training\r\n",
      "  --nhwc BOOL                     Use NHWC memory format with FP16\r\n",
      "  --nobench BOOL                  Disable cuDNN benchmarking\r\n",
      "  --allow-tf32 BOOL               Allow PyTorch to use TF32 internally\r\n",
      "  --workers INT                   Override number of DataLoader workers\r\n",
      "  --help                          Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86aa7f",
   "metadata": {
    "papermill": {
     "duration": 0.096593,
     "end_time": "2022-02-19T20:25:05.443781",
     "exception": false,
     "start_time": "2022-02-19T20:25:05.347188",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "eb86aa7f"
   },
   "source": [
    "### Training will take a long time, make sure you have enough GPU hours available (minimum 10 hours required for good results)\n",
    "Do !python train.py --help to see the different optional arguments available.\n",
    "\n",
    "Resume from your previous checkpoint of notebook times out. Get output model from: ./stylegan2-ada-pytorch/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6395a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T20:25:05.643821Z",
     "iopub.status.busy": "2022-02-19T20:25:05.642952Z",
     "iopub.status.idle": "2022-02-20T06:58:41.989366Z",
     "shell.execute_reply": "2022-02-20T06:58:41.988793Z",
     "shell.execute_reply.started": "2022-02-19T20:18:43.228655Z"
    },
    "papermill": {
     "duration": 38016.450103,
     "end_time": "2022-02-20T06:58:41.989539",
     "exception": false,
     "start_time": "2022-02-19T20:25:05.539436",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "72c6395a",
    "outputId": "799aaa1d-f314-410c-9626-2f4e70296298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Training options:\r\n",
      "{\r\n",
      "  \"num_gpus\": 1,\r\n",
      "  \"image_snapshot_ticks\": 4,\r\n",
      "  \"network_snapshot_ticks\": 4,\r\n",
      "  \"metrics\": [],\r\n",
      "  \"random_seed\": 0,\r\n",
      "  \"training_set_kwargs\": {\r\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\r\n",
      "    \"path\": \"./datasets/ganyu.zip\",\r\n",
      "    \"use_labels\": false,\r\n",
      "    \"max_size\": 850,\r\n",
      "    \"xflip\": true,\r\n",
      "    \"resolution\": 512\r\n",
      "  },\r\n",
      "  \"data_loader_kwargs\": {\r\n",
      "    \"pin_memory\": true,\r\n",
      "    \"num_workers\": 3,\r\n",
      "    \"prefetch_factor\": 2\r\n",
      "  },\r\n",
      "  \"G_kwargs\": {\r\n",
      "    \"class_name\": \"training.networks.Generator\",\r\n",
      "    \"z_dim\": 512,\r\n",
      "    \"w_dim\": 512,\r\n",
      "    \"mapping_kwargs\": {\r\n",
      "      \"num_layers\": 8\r\n",
      "    },\r\n",
      "    \"synthesis_kwargs\": {\r\n",
      "      \"channel_base\": 32768,\r\n",
      "      \"channel_max\": 512,\r\n",
      "      \"num_fp16_res\": 4,\r\n",
      "      \"conv_clamp\": 256\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"D_kwargs\": {\r\n",
      "    \"class_name\": \"training.networks.Discriminator\",\r\n",
      "    \"block_kwargs\": {},\r\n",
      "    \"mapping_kwargs\": {},\r\n",
      "    \"epilogue_kwargs\": {\r\n",
      "      \"mbstd_group_size\": 8\r\n",
      "    },\r\n",
      "    \"channel_base\": 32768,\r\n",
      "    \"channel_max\": 512,\r\n",
      "    \"num_fp16_res\": 4,\r\n",
      "    \"conv_clamp\": 256\r\n",
      "  },\r\n",
      "  \"G_opt_kwargs\": {\r\n",
      "    \"class_name\": \"torch.optim.Adam\",\r\n",
      "    \"lr\": 0.0025,\r\n",
      "    \"betas\": [\r\n",
      "      0,\r\n",
      "      0.99\r\n",
      "    ],\r\n",
      "    \"eps\": 1e-08\r\n",
      "  },\r\n",
      "  \"D_opt_kwargs\": {\r\n",
      "    \"class_name\": \"torch.optim.Adam\",\r\n",
      "    \"lr\": 0.0025,\r\n",
      "    \"betas\": [\r\n",
      "      0,\r\n",
      "      0.99\r\n",
      "    ],\r\n",
      "    \"eps\": 1e-08\r\n",
      "  },\r\n",
      "  \"loss_kwargs\": {\r\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\r\n",
      "    \"r1_gamma\": 0.5\r\n",
      "  },\r\n",
      "  \"total_kimg\": 145,\r\n",
      "  \"batch_size\": 64,\r\n",
      "  \"batch_gpu\": 8,\r\n",
      "  \"ema_kimg\": 20,\r\n",
      "  \"ema_rampup\": null,\r\n",
      "  \"ada_target\": 0.6,\r\n",
      "  \"augment_kwargs\": {\r\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\r\n",
      "    \"xflip\": 1,\r\n",
      "    \"rotate90\": 1,\r\n",
      "    \"xint\": 1,\r\n",
      "    \"scale\": 1,\r\n",
      "    \"rotate\": 1,\r\n",
      "    \"aniso\": 1,\r\n",
      "    \"xfrac\": 1\r\n",
      "  },\r\n",
      "  \"resume_pkl\": \"/kaggle/input/ganyu-genshin-impact-anime-faces-gan-training/rem-pretrained.pkl\",\r\n",
      "  \"ada_kimg\": 100,\r\n",
      "  \"run_dir\": \"./results/00000-ganyu-mirror-paper512-kimg145-bg-resumecustom\"\r\n",
      "}\r\n",
      "\r\n",
      "Output directory:   ./results/00000-ganyu-mirror-paper512-kimg145-bg-resumecustom\r\n",
      "Training data:      ./datasets/ganyu.zip\r\n",
      "Training duration:  145 kimg\r\n",
      "Number of GPUs:     1\r\n",
      "Number of images:   850\r\n",
      "Image resolution:   512\r\n",
      "Conditional model:  False\r\n",
      "Dataset x-flips:    True\r\n",
      "\r\n",
      "Creating output directory...\r\n",
      "Launching processes...\r\n",
      "Loading training set...\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  cpuset_checked))\r\n",
      "\r\n",
      "Num images:  1700\r\n",
      "Image shape: [3, 512, 512]\r\n",
      "Label shape: [0]\r\n",
      "\r\n",
      "Constructing networks...\r\n",
      "Resuming from \"/kaggle/input/ganyu-genshin-impact-anime-faces-gan-training/rem-pretrained.pkl\"\r\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\r\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\r\n",
      "\r\n",
      "Generator             Parameters  Buffers  Output shape        Datatype\r\n",
      "---                   ---         ---      ---                 ---     \r\n",
      "mapping.fc0           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc1           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc2           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc3           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc4           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc5           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc6           262656      -        [8, 512]            float32 \r\n",
      "mapping.fc7           262656      -        [8, 512]            float32 \r\n",
      "mapping               -           512      [8, 16, 512]        float32 \r\n",
      "synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 \r\n",
      "synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 \r\n",
      "synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 \r\n",
      "synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 \r\n",
      "synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 \r\n",
      "synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 \r\n",
      "synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 \r\n",
      "synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 \r\n",
      "synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 \r\n",
      "synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 \r\n",
      "synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 \r\n",
      "synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 \r\n",
      "synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 \r\n",
      "synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 \r\n",
      "synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float32 \r\n",
      "synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float32 \r\n",
      "synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float32 \r\n",
      "synthesis.b32:0       -           16       [8, 512, 32, 32]    float32 \r\n",
      "synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 \r\n",
      "synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 \r\n",
      "synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 \r\n",
      "synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 \r\n",
      "synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 \r\n",
      "synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 \r\n",
      "synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 \r\n",
      "synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 \r\n",
      "synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 \r\n",
      "synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 \r\n",
      "synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 \r\n",
      "synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 \r\n",
      "synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 \r\n",
      "synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 \r\n",
      "synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 \r\n",
      "synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 \r\n",
      "synthesis.b512.conv0  139457      262160   [8, 64, 512, 512]   float16 \r\n",
      "synthesis.b512.conv1  69761       262160   [8, 64, 512, 512]   float16 \r\n",
      "synthesis.b512.torgb  33027       -        [8, 3, 512, 512]    float16 \r\n",
      "synthesis.b512:0      -           16       [8, 64, 512, 512]   float16 \r\n",
      "synthesis.b512:1      -           -        [8, 64, 512, 512]   float32 \r\n",
      "---                   ---         ---      ---                 ---     \r\n",
      "Total                 30276583    699904   -                   -       \r\n",
      "\r\n",
      "\r\n",
      "Discriminator  Parameters  Buffers  Output shape        Datatype\r\n",
      "---            ---         ---      ---                 ---     \r\n",
      "b512.fromrgb   256         16       [8, 64, 512, 512]   float16 \r\n",
      "b512.skip      8192        16       [8, 128, 256, 256]  float16 \r\n",
      "b512.conv0     36928       16       [8, 64, 512, 512]   float16 \r\n",
      "b512.conv1     73856       16       [8, 128, 256, 256]  float16 \r\n",
      "b512           -           16       [8, 128, 256, 256]  float16 \r\n",
      "b256.skip      32768       16       [8, 256, 128, 128]  float16 \r\n",
      "b256.conv0     147584      16       [8, 128, 256, 256]  float16 \r\n",
      "b256.conv1     295168      16       [8, 256, 128, 128]  float16 \r\n",
      "b256           -           16       [8, 256, 128, 128]  float16 \r\n",
      "b128.skip      131072      16       [8, 512, 64, 64]    float16 \r\n",
      "b128.conv0     590080      16       [8, 256, 128, 128]  float16 \r\n",
      "b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \r\n",
      "b128           -           16       [8, 512, 64, 64]    float16 \r\n",
      "b64.skip       262144      16       [8, 512, 32, 32]    float16 \r\n",
      "b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \r\n",
      "b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \r\n",
      "b64            -           16       [8, 512, 32, 32]    float16 \r\n",
      "b32.skip       262144      16       [8, 512, 16, 16]    float32 \r\n",
      "b32.conv0      2359808     16       [8, 512, 32, 32]    float32 \r\n",
      "b32.conv1      2359808     16       [8, 512, 16, 16]    float32 \r\n",
      "b32            -           16       [8, 512, 16, 16]    float32 \r\n",
      "b16.skip       262144      16       [8, 512, 8, 8]      float32 \r\n",
      "b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \r\n",
      "b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \r\n",
      "b16            -           16       [8, 512, 8, 8]      float32 \r\n",
      "b8.skip        262144      16       [8, 512, 4, 4]      float32 \r\n",
      "b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \r\n",
      "b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \r\n",
      "b8             -           16       [8, 512, 4, 4]      float32 \r\n",
      "b4.mbstd       -           -        [8, 513, 4, 4]      float32 \r\n",
      "b4.conv        2364416     16       [8, 512, 4, 4]      float32 \r\n",
      "b4.fc          4194816     -        [8, 512]            float32 \r\n",
      "b4.out         513         -        [8, 1]              float32 \r\n",
      "---            ---         ---      ---                 ---     \r\n",
      "Total          28982849    480      -                   -       \r\n",
      "\r\n",
      "Setting up augmentation...\r\n",
      "Distributing across 1 GPUs...\r\n",
      "Setting up training phases...\r\n",
      "Exporting sample images...\r\n",
      "Initializing logs...\r\n",
      "Training for 145 kimg...\r\n",
      "\r\n",
      "tick 0     kimg 0.1      time 2m 21s       sec/tick 33.7    sec/kimg 526.78  maintenance 107.7  cpumem 4.63   gpumem 10.51  augment 0.000\r\n",
      "tick 1     kimg 4.1      time 19m 57s      sec/tick 1033.0  sec/kimg 256.21  maintenance 22.4   cpumem 5.36   gpumem 7.89   augment 0.013\r\n",
      "tick 2     kimg 8.1      time 37m 22s      sec/tick 1044.9  sec/kimg 259.15  maintenance 0.0    cpumem 5.36   gpumem 7.88   augment 0.036\r\n",
      "tick 3     kimg 12.2     time 54m 48s      sec/tick 1045.5  sec/kimg 259.31  maintenance 0.3    cpumem 5.36   gpumem 7.88   augment 0.056\r\n",
      "tick 4     kimg 16.2     time 1h 12m 14s   sec/tick 1046.0  sec/kimg 259.42  maintenance 0.3    cpumem 5.36   gpumem 7.90   augment 0.072\r\n",
      "tick 5     kimg 20.2     time 1h 29m 57s   sec/tick 1041.5  sec/kimg 258.30  maintenance 22.0   cpumem 5.36   gpumem 7.92   augment 0.082\r\n",
      "tick 6     kimg 24.3     time 1h 47m 24s   sec/tick 1046.6  sec/kimg 259.57  maintenance 0.0    cpumem 5.36   gpumem 7.92   augment 0.100\r\n",
      "tick 7     kimg 28.3     time 2h 04m 51s   sec/tick 1046.6  sec/kimg 259.56  maintenance 0.3    cpumem 5.36   gpumem 8.01   augment 0.110\r\n",
      "tick 8     kimg 32.3     time 2h 22m 18s   sec/tick 1047.0  sec/kimg 259.67  maintenance 0.3    cpumem 5.36   gpumem 7.98   augment 0.120\r\n",
      "tick 9     kimg 36.4     time 2h 40m 03s   sec/tick 1042.6  sec/kimg 258.58  maintenance 22.6   cpumem 5.36   gpumem 8.05   augment 0.141\r\n",
      "tick 10    kimg 40.4     time 2h 57m 30s   sec/tick 1047.1  sec/kimg 259.69  maintenance 0.0    cpumem 5.36   gpumem 8.00   augment 0.143\r\n",
      "tick 11    kimg 44.4     time 3h 14m 58s   sec/tick 1047.3  sec/kimg 259.75  maintenance 0.3    cpumem 5.36   gpumem 8.03   augment 0.154\r\n",
      "tick 12    kimg 48.4     time 3h 32m 26s   sec/tick 1047.4  sec/kimg 259.78  maintenance 0.3    cpumem 5.36   gpumem 7.97   augment 0.174\r\n",
      "tick 13    kimg 52.5     time 3h 50m 12s   sec/tick 1043.3  sec/kimg 258.75  maintenance 23.1   cpumem 5.36   gpumem 8.01   augment 0.200\r\n",
      "tick 14    kimg 56.5     time 4h 07m 40s   sec/tick 1047.8  sec/kimg 259.87  maintenance 0.0    cpumem 5.36   gpumem 8.03   augment 0.238\r\n",
      "tick 15    kimg 60.5     time 4h 25m 08s   sec/tick 1048.2  sec/kimg 259.97  maintenance 0.3    cpumem 5.36   gpumem 8.06   augment 0.274\r\n",
      "tick 16    kimg 64.6     time 4h 42m 38s   sec/tick 1049.2  sec/kimg 260.21  maintenance 0.3    cpumem 5.36   gpumem 8.03   augment 0.305\r\n",
      "tick 17    kimg 68.6     time 5h 00m 19s   sec/tick 1037.4  sec/kimg 257.29  maintenance 24.0   cpumem 5.38   gpumem 8.00   augment 0.325\r\n",
      "tick 18    kimg 72.6     time 5h 17m 48s   sec/tick 1049.3  sec/kimg 260.23  maintenance 0.0    cpumem 5.38   gpumem 8.04   augment 0.343\r\n",
      "tick 19    kimg 76.7     time 5h 35m 18s   sec/tick 1049.5  sec/kimg 260.28  maintenance 0.3    cpumem 5.38   gpumem 8.07   augment 0.353\r\n",
      "tick 20    kimg 80.7     time 5h 52m 48s   sec/tick 1049.4  sec/kimg 260.26  maintenance 0.3    cpumem 5.38   gpumem 8.11   augment 0.379\r\n",
      "tick 21    kimg 84.7     time 6h 10m 37s   sec/tick 1045.0  sec/kimg 259.17  maintenance 24.0   cpumem 5.41   gpumem 8.14   augment 0.394\r\n",
      "tick 22    kimg 88.8     time 6h 28m 07s   sec/tick 1049.9  sec/kimg 260.38  maintenance 0.0    cpumem 5.41   gpumem 8.10   augment 0.402\r\n",
      "tick 23    kimg 92.8     time 6h 45m 37s   sec/tick 1050.0  sec/kimg 260.43  maintenance 0.3    cpumem 5.41   gpumem 8.14   augment 0.412\r\n",
      "tick 24    kimg 96.8     time 7h 03m 08s   sec/tick 1050.1  sec/kimg 260.45  maintenance 0.3    cpumem 5.41   gpumem 8.13   augment 0.417\r\n",
      "tick 25    kimg 100.9    time 7h 20m 56s   sec/tick 1045.3  sec/kimg 259.26  maintenance 23.4   cpumem 5.42   gpumem 8.10   augment 0.428\r\n",
      "tick 26    kimg 104.9    time 7h 38m 26s   sec/tick 1050.0  sec/kimg 260.42  maintenance 0.0    cpumem 5.42   gpumem 8.13   augment 0.430\r\n",
      "tick 27    kimg 108.9    time 7h 55m 57s   sec/tick 1050.0  sec/kimg 260.41  maintenance 0.3    cpumem 5.42   gpumem 8.09   augment 0.425\r\n",
      "tick 28    kimg 113.0    time 8h 13m 27s   sec/tick 1050.0  sec/kimg 260.42  maintenance 0.3    cpumem 5.42   gpumem 8.14   augment 0.425\r\n",
      "tick 29    kimg 117.0    time 8h 31m 15s   sec/tick 1045.2  sec/kimg 259.22  maintenance 22.9   cpumem 5.39   gpumem 8.10   augment 0.430\r\n",
      "tick 30    kimg 121.0    time 8h 48m 45s   sec/tick 1049.9  sec/kimg 260.40  maintenance 0.0    cpumem 5.39   gpumem 8.09   augment 0.443\r\n",
      "tick 31    kimg 125.1    time 9h 06m 15s   sec/tick 1050.1  sec/kimg 260.45  maintenance 0.3    cpumem 5.39   gpumem 8.11   augment 0.458\r\n",
      "tick 32    kimg 129.1    time 9h 23m 46s   sec/tick 1050.3  sec/kimg 260.49  maintenance 0.3    cpumem 5.39   gpumem 8.10   augment 0.474\r\n",
      "tick 33    kimg 133.1    time 9h 41m 27s   sec/tick 1038.8  sec/kimg 257.63  maintenance 22.6   cpumem 5.39   gpumem 8.10   augment 0.489\r\n",
      "tick 34    kimg 137.2    time 9h 58m 58s   sec/tick 1050.7  sec/kimg 260.58  maintenance 0.0    cpumem 5.39   gpumem 8.07   augment 0.471\r\n",
      "tick 35    kimg 141.2    time 10h 16m 29s  sec/tick 1050.7  sec/kimg 260.60  maintenance 0.3    cpumem 5.39   gpumem 8.10   augment 0.481\r\n",
      "tick 36    kimg 145.0    time 10h 33m 10s  sec/tick 1000.7  sec/kimg 260.61  maintenance 0.3    cpumem 5.40   gpumem 8.14   augment 0.484\r\n",
      "\r\n",
      "Exiting...\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir ./results --snap=4 --cfg=paper512 --data=./datasets/ganyu.zip --augpipe=\"bg\" --mirror=True --metrics=None --resume=/kaggle/input/ganyu-genshin-impact-anime-faces-gan-training/rem-pretrained.pkl --augpipe=\"bg\" --kimg=145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193938a",
   "metadata": {
    "papermill": {
     "duration": 0.115212,
     "end_time": "2022-02-20T06:58:42.220549",
     "exception": false,
     "start_time": "2022-02-20T06:58:42.105337",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "4193938a"
   },
   "source": [
    "Stopping training as example notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38091.970309,
   "end_time": "2022-02-20T06:58:42.900625",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-19T20:23:50.930316",
   "version": "2.3.3"
  },
  "colab": {
   "name": "ganyu-face-training-with-stylegan2-ada.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}